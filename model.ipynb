{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pulavartivinay/Face_Mask_Detection/blob/model/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLvQGuk0lNt"
      },
      "source": [
        "# start"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlBnX4vG41B_"
      },
      "source": [
        "# installs"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkpx-z0O434I"
      },
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "from PIL import Image"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JlUtNcCyCth"
      },
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr33kyIi47Cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942441f9-d505-4b20-ca00-b7a921f0f73f"
      },
      "source": [
        "# loading dataset\n",
        "# https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset\n",
        "\n",
        "!gdown --id 1NOzYPR3zAS8e2EFdRvjYpSBxg9RaDfxe #loading the dataset from google drive link to colab\n",
        "!unzip /content/face-mask-12k.zip &> /dev/null #unzipping\n",
        "!rm -rf /content/face-mask-12k.zip &> /dev/null #deleting the zip file\n",
        "!rm -rf __MACOSX &> /dev/null"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NOzYPR3zAS8e2EFdRvjYpSBxg9RaDfxe\n",
            "To: /content/face-mask-12k.zip\n",
            "351MB [00:02, 170MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPlA907iyE7k"
      },
      "source": [
        "## Finding Correct Dimension for input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StHWT0FEI7T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37897c5a-a82c-4039-f57c-61087da70cc7"
      },
      "source": [
        "# finding the perfect crop size, for whole dataset\n",
        "# https://stackoverflow.com/questions/19098104/python-opencv2-cv2-wrapper-to-get-image-size\n",
        "\n",
        "def generate_image_paths(dir_path):\n",
        "  files_png = glob.glob(dir_path + '/**/*.png', recursive=True)\n",
        "  paths = list(files_png)\n",
        "  return paths\n",
        "\n",
        "train_dataset_path = \"/content/face-mask-12k/Train\"\n",
        "val_dataset_path = \"/content/face-mask-12k/Validation\"\n",
        "\n",
        "train_paths = generate_image_paths(train_dataset_path)\n",
        "val_paths = generate_image_paths(val_dataset_path)\n",
        "\n",
        "print(\"Images in Train Dataset \", len(train_paths)) #output: 10000\n",
        "print(\"Images in Val Dataset\", len(val_paths))   #output: 800\n",
        "\n",
        "def find_avg_height_and_width(paths):\n",
        "  sum_height = 0\n",
        "  sum_width = 0\n",
        "  for path in paths:\n",
        "    image = cv2.imread(path)\n",
        "    height, width, channels = image.shape\n",
        "    sum_height += height\n",
        "    sum_width += width\n",
        "  avg_height = sum_height//len(paths)\n",
        "  avg_width = sum_width//len(paths)\n",
        "  return (avg_height, avg_width)\n",
        "\n",
        "print(\"Train avg height and width\", find_avg_height_and_width(train_paths)) #output: (153, 153)\n",
        "print(\"Validation avg height and width\", find_avg_height_and_width(val_paths)) #output: (152, 152)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images in Train Dataset  10000\n",
            "Images in Val Dataset 800\n",
            "Train avg height and width (153, 153)\n",
            "Validation avg height and width (152, 152)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herMZvZ3yMVw"
      },
      "source": [
        "## Hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dku1vQ47ElLC"
      },
      "source": [
        "# hyper parameters\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "img_dim = 224"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OdYpioeyOc9"
      },
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ab3ejV4-yQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67f0ccc-fc83-4f08-8526-67b74db45f01"
      },
      "source": [
        "# Preprocessing the data set into list of images\n",
        "# https://keras.io/api/preprocessing/image/#image_dataset_from_directory-function\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/face-mask-12k/Train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_dim, img_dim),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"nearest\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/face-mask-12k/Validation\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_dim, img_dim),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"nearest\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "print(\"Train-dataset-length\", len(train_dataset))\n",
        "print(\"Validation-dataset-length\", len(val_dataset))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 800 files belonging to 2 classes.\n",
            "Train-dataset-length 625\n",
            "Validation-dataset-length 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mjCVJ0P5KYH"
      },
      "source": [
        "# Model(Transfer Learning) (Later)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl0UEJjppo79"
      },
      "source": [
        "# Adding call Back Functions\n",
        "# https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "\n",
        "# def recall_m(y_true, y_pred):\n",
        "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "#     recall = true_positives / (possible_positives + K.epsilon())\n",
        "#     return recall\n",
        "\n",
        "# def precision_m(y_true, y_pred):\n",
        "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
        "#     return precision\n",
        "\n",
        "# def f1_m(y_true, y_pred):\n",
        "#     precision = precision_m(y_true, y_pred)\n",
        "#     recall = recall_m(y_true, y_pred)\n",
        "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShR4aOVByR4L"
      },
      "source": [
        "## Main Model Class with utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VBi3RS35Xi6"
      },
      "source": [
        "# Main Model \n",
        "\n",
        "class MModel:\n",
        "  def __init__(self, input_shape):\n",
        "    self.input_shape = input_shape\n",
        "    self.model = self.get_model()\n",
        "    self.train_history = []\n",
        "    self.val_history = []\n",
        "    self.test_history = []\n",
        "\n",
        "  def get_transfer_learning(self):\n",
        "    mobilenetv2 = tf.keras.applications.MobileNetV2(input_shape=self.input_shape, include_top=False, weights=\"imagenet\")\n",
        "    mobilenetv2.trainable = False\n",
        "    return mobilenetv2\n",
        "\n",
        "  def get_model(self):\n",
        "    mobilenetv2 = self.get_transfer_learning()\n",
        "\n",
        "    inputs = tf.keras.Input(shape=self.input_shape)  #input layer\n",
        "    rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./255.)(inputs)\n",
        "    base_model = mobilenetv2(rescale)\n",
        "    conv1 = tf.keras.layers.Conv2D(filters=8, kernel_size=2, strides=(1, 1), padding=\"valid\")(base_model)\n",
        "    norm1 = tf.keras.layers.BatchNormalization()(conv1)\n",
        "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding=\"valid\")(norm1)\n",
        "    drop1 = tf.keras.layers.Dropout(rate=0.1)(pool1)\n",
        "    flat1 = tf.keras.layers.Flatten()(drop1)\n",
        "    norm2 = tf.keras.layers.BatchNormalization()(flat1)\n",
        "    dense1 = tf.keras.layers.Dense(32, activation='relu')(norm2)\n",
        "    outputs = tf.keras.layers.Dense(2, activation='softmax')(dense1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.summary()\n",
        "    # plot_model(model, to_file='main_model_V040301.png') #convention for the model plot: main_model_VddMMXX where XX is the model number\n",
        "    return model\n",
        "\n",
        "  def compile(self, optimizer, loss, metrics):\n",
        "    self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "  def train(self, train_dataset, train_batch_size, val_dataset, val_batch_size, epochs):\n",
        "    self.train_history = self.model.fit(train_dataset, batch_size=train_batch_size, validation_data=val_dataset, validation_batch_size=val_batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "  def evaluate(self, val_dataset, batch_size):\n",
        "    self.val_history = self.model.evaluate(val_dataset, batch_size, verbose=1)\n",
        "\n",
        "  def predict_single(self, image):\n",
        "    \"\"\"\n",
        "      image dimensions should be (224, 224, 3)\n",
        "    \"\"\"\n",
        "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    input_arr = np.array([input_arr])\n",
        "    p = self.model.predict(input_arr, verbose = 0)\n",
        "    return p\n",
        "\n",
        "  def plot_loss_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[0])\n",
        "    plt.plot(list(self.train_history.history.values())[4])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def plot_accuracy_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[1])\n",
        "    plt.plot(list(self.train_history.history.values())[5])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def plot_f1_per_epoch(self):\n",
        "    plt.plot(self.train_history.history['f1'])\n",
        "    plt.title('model f1_score')\n",
        "    plt.ylabel('f1')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "  \n",
        "  def plot_precision_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[2])\n",
        "    plt.plot(list(self.train_history.history.values())[6])\n",
        "    plt.title('model precision_score')\n",
        "    plt.ylabel('precision')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def plot_recall_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[3])\n",
        "    plt.plot(list(self.train_history.history.values())[7])\n",
        "    plt.title('model recall_score')\n",
        "    plt.ylabel('recall')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def write_model_with_weights_to_file(self, filepath):\n",
        "    self.model.save(filepath)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHCnbshYFL9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c130789c-d8f0-40b6-d9ec-f35c23becdf5"
      },
      "source": [
        "# Creating instance of MModel Class\n",
        "\n",
        "mmodel = MModel((224, 224, 3))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_39 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "rescaling_17 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 6, 6, 8)           40968     \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 6, 6, 8)           32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 3, 3, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 3, 3, 8)           0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 72)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 72)                288       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 32)                2336      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 2,301,674\n",
            "Trainable params: 43,530\n",
            "Non-trainable params: 2,258,144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNZ31Tj15buP"
      },
      "source": [
        "# Model Compilation\n",
        "# https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "mmodel.compile(opt, \"categorical_crossentropy\", ['acc'])"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGkav6A-yWGR"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFgDxtDw5epa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff5c2f9-4c15-442a-c5e4-743ed88404e6"
      },
      "source": [
        "# Training\n",
        "# https://keras.io/api/models/model_training_apis/\n",
        "epochs=100\n",
        "mmodel.train(train_dataset, batch_size, val_dataset, -1, epochs)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 47s 70ms/step - loss: 0.5158 - acc: 0.7497 - val_loss: 0.2381 - val_acc: 0.9125\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.2173 - acc: 0.9179 - val_loss: 0.1464 - val_acc: 0.9500\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.1584 - acc: 0.9451 - val_loss: 0.1048 - val_acc: 0.9625\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.1196 - acc: 0.9611 - val_loss: 0.0812 - val_acc: 0.9737\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0934 - acc: 0.9724 - val_loss: 0.0653 - val_acc: 0.9800\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0818 - acc: 0.9748 - val_loss: 0.0541 - val_acc: 0.9837\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0701 - acc: 0.9787 - val_loss: 0.0456 - val_acc: 0.9850\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 45s 72ms/step - loss: 0.0622 - acc: 0.9813 - val_loss: 0.0396 - val_acc: 0.9862\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 45s 72ms/step - loss: 0.0524 - acc: 0.9838 - val_loss: 0.0354 - val_acc: 0.9887\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0483 - acc: 0.9852 - val_loss: 0.0323 - val_acc: 0.9887\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0418 - acc: 0.9882 - val_loss: 0.0290 - val_acc: 0.9900\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0415 - acc: 0.9877 - val_loss: 0.0263 - val_acc: 0.9900\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0369 - acc: 0.9895 - val_loss: 0.0248 - val_acc: 0.9900\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0355 - acc: 0.9895 - val_loss: 0.0224 - val_acc: 0.9925\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0329 - acc: 0.9895 - val_loss: 0.0212 - val_acc: 0.9925\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0306 - acc: 0.9905 - val_loss: 0.0200 - val_acc: 0.9925\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0309 - acc: 0.9898 - val_loss: 0.0188 - val_acc: 0.9925\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0250 - acc: 0.9913 - val_loss: 0.0182 - val_acc: 0.9925\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0171 - val_acc: 0.9950\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0225 - acc: 0.9934 - val_loss: 0.0158 - val_acc: 0.9925\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0152 - val_acc: 0.9937\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0208 - acc: 0.9940 - val_loss: 0.0153 - val_acc: 0.9937\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0243 - acc: 0.9916 - val_loss: 0.0157 - val_acc: 0.9937\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0176 - acc: 0.9954 - val_loss: 0.0140 - val_acc: 0.9950\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.0140 - val_acc: 0.9937\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0140 - val_acc: 0.9950\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0138 - val_acc: 0.9937\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0146 - acc: 0.9956 - val_loss: 0.0142 - val_acc: 0.9937\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0122 - acc: 0.9967 - val_loss: 0.0122 - val_acc: 0.9937\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0143 - acc: 0.9962 - val_loss: 0.0128 - val_acc: 0.9950\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0128 - val_acc: 0.9950\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.0113 - val_acc: 0.9937\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0135 - acc: 0.9963 - val_loss: 0.0106 - val_acc: 0.9950\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0120 - val_acc: 0.9950\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0121 - val_acc: 0.9950\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 44s 69ms/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0116 - val_acc: 0.9950\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0132 - acc: 0.9962 - val_loss: 0.0101 - val_acc: 0.9950\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0107 - val_acc: 0.9950\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.0101 - val_acc: 0.9950\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0097 - val_acc: 0.9962\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0103 - acc: 0.9975 - val_loss: 0.0098 - val_acc: 0.9962\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0099 - val_acc: 0.9962\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0109 - val_acc: 0.9950\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0124 - acc: 0.9954 - val_loss: 0.0085 - val_acc: 0.9962\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0107 - val_acc: 0.9950\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0104 - acc: 0.9962 - val_loss: 0.0101 - val_acc: 0.9950\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0105 - acc: 0.9971 - val_loss: 0.0102 - val_acc: 0.9950\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0096 - val_acc: 0.9950\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0101 - val_acc: 0.9950\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0092 - val_acc: 0.9950\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0090 - val_acc: 0.9962\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0085 - val_acc: 0.9962\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0083 - val_acc: 0.9962\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0096 - val_acc: 0.9950\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0066 - acc: 0.9984 - val_loss: 0.0084 - val_acc: 0.9950\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0098 - val_acc: 0.9950\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0087 - val_acc: 0.9962\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0085 - val_acc: 0.9950\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0092 - val_acc: 0.9950\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0091 - val_acc: 0.9950\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0097 - val_acc: 0.9950\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0091 - val_acc: 0.9950\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0082 - val_acc: 0.9962\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0090 - val_acc: 0.9950\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0105 - val_acc: 0.9950\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9950\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0088 - val_acc: 0.9962\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0088 - val_acc: 0.9950\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0073 - acc: 0.9975 - val_loss: 0.0093 - val_acc: 0.9950\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0076 - val_acc: 0.9950\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0084 - val_acc: 0.9950\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0093 - val_acc: 0.9950\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0084 - val_acc: 0.9950\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0090 - val_acc: 0.9962\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9962\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9962\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0123 - val_acc: 0.9950\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0103 - val_acc: 0.9950\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0093 - val_acc: 0.9950\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0095 - val_acc: 0.9950\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0090 - val_acc: 0.9962\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0089 - val_acc: 0.9962\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0088 - val_acc: 0.9962\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0105 - val_acc: 0.9950\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0106 - val_acc: 0.9962\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9962\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 44s 69ms/step - loss: 0.0032 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9962\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0098 - val_acc: 0.9962\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 0.9950\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0102 - val_acc: 0.9950\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0088 - val_acc: 0.9962\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0087 - val_acc: 0.9962\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 44s 69ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9950\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0067 - val_acc: 0.9962\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0072 - val_acc: 0.9962\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0098 - val_acc: 0.9950\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0089 - val_acc: 0.9950\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 43s 68ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0089 - val_acc: 0.9962\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 44s 70ms/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0106 - val_acc: 0.9950\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 44s 69ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh-vffHwvMA_",
        "outputId": "5c16f7f0-380f-4a8d-80cd-248d79d9dbfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i=0\n",
        "start = time.time()\n",
        "\n",
        "'''measuring time'''\n",
        "img = Image.open(val_paths[i])\n",
        "img.resize((img_dim, img_dim), Image.NEAREST)\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "input_arr = np.array([input_arr])\n",
        "p = mmodel.model.predict(input_arr, verbose = 1)\n",
        "\n",
        "end = time.time()\n",
        "print(\"time elapsed \", end - start)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "time elapsed  0.05969738960266113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bonkvcKyX_3"
      },
      "source": [
        "## Inferring Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Xvxsds5grG"
      },
      "source": [
        "# Predictions of Validation data set(Dev) - visualisation\n",
        "\n",
        "i = 0\n",
        "for batch in val_dataset:\n",
        "  for i in range(batch_size):\n",
        "    rgb_image = batch[0][i]\n",
        "    label = batch[1][i].numpy()[0]\n",
        "\n",
        "    bgr_image = cv2.cvtColor(rgb_image.numpy(), cv2.COLOR_RGB2BGR)\n",
        "    cv2_imshow(bgr_image)\n",
        "\n",
        "    print(\"Ground Truth\", label)\n",
        "    print(\"Prediction\", mmodel.predict_single(rgb_image))\n",
        "    i+=1\n",
        "  if i>=10:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPc_NZXNyaI_"
      },
      "source": [
        "## More inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZDmMDzt6P05"
      },
      "source": [
        "# Drawing the train Loss, accuracy, f1, precision, recall of the model - visualising\n",
        "\n",
        "mmodel.plot_loss_per_epoch()\n",
        "mmodel.plot_accuracy_per_epoch()\n",
        "# mmodel.plot_f1_per_epoch()\n",
        "# mmodel.plot_precision_per_epoch()\n",
        "# mmodel.plot_recall_per_epoch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOjdC6MYVqOg"
      },
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZiO-dJLGRkO",
        "outputId": "3b5b5597-6031-4cd5-d72a-fe2fb5dbe2c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# saving model to file\n",
        "\n",
        "mmodel.write_model_with_weights_to_file('facemask12k_100epochs_mobilenetv2_224_rescaled_0.05s.h5')"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDHJAPtpycJf"
      },
      "source": [
        "## Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXHMbwPmqJtP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}