{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "streamModel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEF8DqPA0+A9R3fl6RdAAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pulavartivinay/Face_Mask_Detection/blob/stream/streamModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYKr6D7b5_Y4"
      },
      "source": [
        "# start"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gb7kwml6fpW"
      },
      "source": [
        "# installs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAHeVNlU6hjG"
      },
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "from keras.utils import plot_model\n",
        "from keras.models import model_from_json\n",
        "from keras import backend as K\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia0qTTCs6iuX",
        "outputId": "eac51ea9-2694-48da-c254-3d6b2f6bc2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# loading dataset\n",
        "# https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset\n",
        "\n",
        "!gdown --id 1NOzYPR3zAS8e2EFdRvjYpSBxg9RaDfxe #loading the dataset from google drive link to colab\n",
        "!unzip /content/face-mask-12k.zip &> /dev/null #unzipping\n",
        "!rm -rf /content/face-mask-12k.zip &> /dev/null #deleting the zip file\n",
        "!rm -rf __MACOSX &> /dev/null"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NOzYPR3zAS8e2EFdRvjYpSBxg9RaDfxe\n",
            "To: /content/face-mask-12k.zip\n",
            "351MB [00:04, 81.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU4VN0qv6mvO"
      },
      "source": [
        "# hyper parameters\n",
        "epochs = 10\n",
        "batch_size = 32"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kLSis6D6mtU",
        "outputId": "6b03eed0-8b23-42aa-f48f-a34c38fbbf07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# finding the perfect crop size, for whole dataset\n",
        "# https://stackoverflow.com/questions/19098104/python-opencv2-cv2-wrapper-to-get-image-size\n",
        "\n",
        "def generate_image_paths(dir_path):\n",
        "  files_png = glob.glob(dir_path + '/**/*.png', recursive=True)\n",
        "  paths = list(files_png)\n",
        "  return paths\n",
        "\n",
        "train_dataset_path = \"/content/face-mask-12k/Train\"\n",
        "val_dataset_path = \"/content/face-mask-12k/Validation\"\n",
        "\n",
        "train_paths = generate_image_paths(train_dataset_path)\n",
        "val_paths = generate_image_paths(val_dataset_path)\n",
        "\n",
        "print(len(train_paths)) #output: 10000\n",
        "print(len(val_paths))   #output: 800\n",
        "\n",
        "def find_avg_height_and_width(paths):\n",
        "  sum_height = 0\n",
        "  sum_width = 0\n",
        "  for path in paths:\n",
        "    image = cv2.imread(path)\n",
        "    height, width, channels = image.shape\n",
        "    sum_height += height\n",
        "    sum_width += width\n",
        "  avg_height = sum_height//len(paths)\n",
        "  avg_width = sum_width//len(paths)\n",
        "  return (avg_height, avg_width)\n",
        "\n",
        "print(\"Train avg height and width\", find_avg_height_and_width(train_paths)) #output: (153, 153)\n",
        "print(\"Validation avg height and width\", find_avg_height_and_width(val_paths)) #output: (152, 152)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "800\n",
            "Train avg height and width (153, 153)\n",
            "Validation avg height and width (152, 152)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsJo_qbm6zrR",
        "outputId": "1e0ceda1-56ad-4bb0-d76d-0713b4c74061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preprocessing the data set into list of images\n",
        "# https://keras.io/api/preprocessing/image/#image_dataset_from_directory-function\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/face-mask-12k/Train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(153, 153),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/face-mask-12k/Validation\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    image_size=(153, 153),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "print(\"Train-dataset-length\", len(train_dataset))\n",
        "print(\"Validation-dataset-length\", len(val_dataset))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 800 files belonging to 2 classes.\n",
            "Train-dataset-length 313\n",
            "Validation-dataset-length 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIigOqs62XM"
      },
      "source": [
        "# Stream Model \n",
        "\n",
        "class SModel:\n",
        "  def __init__(self, input_shape):\n",
        "    self.input_shape = input_shape\n",
        "    self.model = self.get_model()\n",
        "    self.train_history = []\n",
        "    self.val_history = []\n",
        "    self.test_history = []\n",
        "\n",
        "\n",
        "  def get_model(self):\n",
        "    inputs = tf.keras.Input(shape=self.input_shape)  #input layer\n",
        "    base_model = tf.keras.applications.Xception(\n",
        "                weights='imagenet',\n",
        "                input_shape=self.input_shape,\n",
        "                include_top=False)(inputs)\n",
        "    layer1 = tf.keras.layers.Conv2D(\n",
        "        filters=2,\n",
        "        kernel_size=4,\n",
        "        strides=(1, 1),\n",
        "        padding=\"valid\",\n",
        "        data_format=None,\n",
        "        dilation_rate=(1, 1),\n",
        "        groups=1,\n",
        "        activation='relu',\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "    )(base_model)\n",
        "    batch_normalization_layer1 = tf.keras.layers.BatchNormalization()(layer1)\n",
        "    max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid')(batch_normalization_layer1)\n",
        "    drop_out_layer1 = tf.keras.layers.Dropout(rate=0.1)(max_pool_2d)\n",
        "    layer2 = tf.keras.layers.Flatten()(drop_out_layer1)\n",
        "    batch_normalization_layer2 = tf.keras.layers.BatchNormalization()(layer2)\n",
        "    Dense_layer1 = tf.keras.layers.Dense(\n",
        "        84,\n",
        "        activation='relu',\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "    )(batch_normalization_layer2)\n",
        "    outputs = tf.keras.layers.Dense(\n",
        "        1,\n",
        "        activation='sigmoid',\n",
        "        use_bias=True,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "    )(Dense_layer1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.summary()\n",
        "    plot_model(model, to_file='main_model_V040301.png') #convention for the model plot: main_model_VddMMXX where XX is the model number\n",
        "    return model\n",
        "\n",
        "  def compile(self, optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['acc', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]):\n",
        "    self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "  def train(self, train_dataset, epochs=1):\n",
        "    self.train_history = self.model.fit(train_dataset, validation_data = val_dataset, epochs=epochs, verbose=1)\n",
        "\n",
        "  def evaluate(self, val_dataset, batch_size=\"32\"):\n",
        "    self.val_history = self.model.evaluate(val_dataset, batch_size=32, verbose=1)\n",
        "\n",
        "  def predict_single(self, image):\n",
        "    \"\"\"\n",
        "      image dimensions should be (153, 153, 3)\n",
        "    \"\"\"\n",
        "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    input_arr = np.array([input_arr])\n",
        "    p = self.model.predict(input_arr, verbose = 0)\n",
        "    return round(p[0][0])\n",
        "\n",
        "  def plot_loss_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[0])\n",
        "    plt.plot(list(self.train_history.history.values())[4])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def plot_accuracy_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[1])\n",
        "    plt.plot(list(self.train_history.history.values())[5])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def plot_f1_per_epoch(self):\n",
        "    plt.plot(self.train_history.history['f1'])\n",
        "    plt.title('model f1_score')\n",
        "    plt.ylabel('f1')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "  \n",
        "  def plot_precision_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[2])\n",
        "    plt.plot(list(self.train_history.history.values())[6])\n",
        "    plt.title('model precision_score')\n",
        "    plt.ylabel('precision')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def plot_recall_per_epoch(self):\n",
        "    plt.plot(list(self.train_history.history.values())[3])\n",
        "    plt.plot(list(self.train_history.history.values())[7])\n",
        "    plt.title('model recall_score')\n",
        "    plt.ylabel('recall')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'])\n",
        "    plt.show()\n",
        "\n",
        "  def write_model_with_weights_to_file(self, filepath):\n",
        "    self.model.save(filepath)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cb6d6S-69Jm",
        "outputId": "8501e0fd-2214-444a-8b7d-49f49f7d9663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating instance of SModel Class\n",
        "\n",
        "mmodel = SModel((153, 153, 3))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 153, 153, 3)]     0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 2)           65538     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 2)           8         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 1, 2)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 2)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 84)                252       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 85        \n",
            "=================================================================\n",
            "Total params: 20,927,371\n",
            "Trainable params: 20,872,835\n",
            "Non-trainable params: 54,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r1x8OmH7Apd"
      },
      "source": [
        "# Model Compilation\n",
        "# https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "mmodel.compile()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV7P1uQo7JDV"
      },
      "source": [
        "# Training\n",
        "# https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "mmodel.train(train_dataset, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwWfS9dv7MIP"
      },
      "source": [
        "# model evaluation on val dataset\n",
        "# https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "mmodel.evaluate(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC_I55307RLj"
      },
      "source": [
        "# Drawing the train Loss, accuracy, precision, recall of the model - visualising\n",
        "\n",
        "mmodel.plot_loss_per_epoch()\n",
        "mmodel.plot_accuracy_per_epoch()\n",
        "mmodel.plot_precision_per_epoch()\n",
        "mmodel.plot_recall_per_epoch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psjRIRsI7VdJ"
      },
      "source": [
        "# saving model to file\n",
        "\n",
        "mmodel.write_model_with_weights_to_file('smodel0.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}